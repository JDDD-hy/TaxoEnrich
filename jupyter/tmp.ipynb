{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 3, 4, 3, 1, 2, 2, 3, 3, 2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BIM(nn.Module):\n",
    "    def __init__(self, l_dim, r_dim):\n",
    "        super(BIM, self).__init__()\n",
    "        self.W = nn.Bilinear(l_dim*2, r_dim, 1, bias=False)\n",
    "        \n",
    "    def forward(self, e1, e2, q):\n",
    "        \"\"\"\n",
    "        e1: tensor of size (*, l_dim)\n",
    "        e2: tensor of size (*, r_dim)\n",
    "\n",
    "        return: tensor of size (*, 1)\n",
    "        \"\"\"\n",
    "        e = torch.cat((e1, e2), -1)\n",
    "        return self.W(e, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "mask = torch.arange(5).expand(10,5)<torch.randint(5,(10,)).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4],\n",
       "        [4],\n",
       "        [0],\n",
       "        [4],\n",
       "        [0],\n",
       "        [2],\n",
       "        [0],\n",
       "        [3],\n",
       "        [4],\n",
       "        [0]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(5,(10,)).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3, 4],\n",
       "        [0, 1, 2, 3, 4],\n",
       "        [0, 1, 2, 3, 4],\n",
       "        [0, 1, 2, 3, 4],\n",
       "        [0, 1, 2, 3, 4],\n",
       "        [0, 1, 2, 3, 4],\n",
       "        [0, 1, 2, 3, 4],\n",
       "        [0, 1, 2, 3, 4],\n",
       "        [0, 1, 2, 3, 4],\n",
       "        [0, 1, 2, 3, 4]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(5).expand(10,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "bil = torch.nn.Bilinear(5,5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "A0 = torch.rand(8,5)\n",
    "B = torch.rand(8,4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2789, 0.1589, 0.0803, 0.0104, 0.4484],\n",
       "         [0.2789, 0.1589, 0.0803, 0.0104, 0.4484],\n",
       "         [0.2789, 0.1589, 0.0803, 0.0104, 0.4484],\n",
       "         [0.2789, 0.1589, 0.0803, 0.0104, 0.4484]],\n",
       "\n",
       "        [[0.8068, 0.8107, 0.1455, 0.7597, 0.2093],\n",
       "         [0.8068, 0.8107, 0.1455, 0.7597, 0.2093],\n",
       "         [0.8068, 0.8107, 0.1455, 0.7597, 0.2093],\n",
       "         [0.8068, 0.8107, 0.1455, 0.7597, 0.2093]],\n",
       "\n",
       "        [[0.9359, 0.2825, 0.0064, 0.9988, 0.5549],\n",
       "         [0.9359, 0.2825, 0.0064, 0.9988, 0.5549],\n",
       "         [0.9359, 0.2825, 0.0064, 0.9988, 0.5549],\n",
       "         [0.9359, 0.2825, 0.0064, 0.9988, 0.5549]],\n",
       "\n",
       "        [[0.0382, 0.1902, 0.6561, 0.8713, 0.1071],\n",
       "         [0.0382, 0.1902, 0.6561, 0.8713, 0.1071],\n",
       "         [0.0382, 0.1902, 0.6561, 0.8713, 0.1071],\n",
       "         [0.0382, 0.1902, 0.6561, 0.8713, 0.1071]],\n",
       "\n",
       "        [[0.6562, 0.6876, 0.5426, 0.8241, 0.1390],\n",
       "         [0.6562, 0.6876, 0.5426, 0.8241, 0.1390],\n",
       "         [0.6562, 0.6876, 0.5426, 0.8241, 0.1390],\n",
       "         [0.6562, 0.6876, 0.5426, 0.8241, 0.1390]],\n",
       "\n",
       "        [[0.8600, 0.8292, 0.9750, 0.9653, 0.7141],\n",
       "         [0.8600, 0.8292, 0.9750, 0.9653, 0.7141],\n",
       "         [0.8600, 0.8292, 0.9750, 0.9653, 0.7141],\n",
       "         [0.8600, 0.8292, 0.9750, 0.9653, 0.7141]],\n",
       "\n",
       "        [[0.0357, 0.8210, 0.0044, 0.1453, 0.3848],\n",
       "         [0.0357, 0.8210, 0.0044, 0.1453, 0.3848],\n",
       "         [0.0357, 0.8210, 0.0044, 0.1453, 0.3848],\n",
       "         [0.0357, 0.8210, 0.0044, 0.1453, 0.3848]],\n",
       "\n",
       "        [[0.7298, 0.0188, 0.9861, 0.7735, 0.4565],\n",
       "         [0.7298, 0.0188, 0.9861, 0.7735, 0.4565],\n",
       "         [0.7298, 0.0188, 0.9861, 0.7735, 0.4565],\n",
       "         [0.7298, 0.0188, 0.9861, 0.7735, 0.4565]]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.functional.softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1522],\n",
       "         [ 0.0375],\n",
       "         [ 0.1015],\n",
       "         [ 0.1446]],\n",
       "\n",
       "        [[-0.2623],\n",
       "         [ 0.7441],\n",
       "         [ 0.2098],\n",
       "         [ 0.8267]],\n",
       "\n",
       "        [[ 0.1457],\n",
       "         [-0.1468],\n",
       "         [-0.1154],\n",
       "         [ 0.4992]],\n",
       "\n",
       "        [[ 0.1788],\n",
       "         [-0.3987],\n",
       "         [ 0.6514],\n",
       "         [-0.3051]],\n",
       "\n",
       "        [[-0.0424],\n",
       "         [ 0.2975],\n",
       "         [ 0.5569],\n",
       "         [ 0.0133]],\n",
       "\n",
       "        [[-0.0905],\n",
       "         [-0.0808],\n",
       "         [ 0.3464],\n",
       "         [ 0.0910]],\n",
       "\n",
       "        [[ 0.0222],\n",
       "         [ 0.3377],\n",
       "         [ 0.1375],\n",
       "         [-0.0044]],\n",
       "\n",
       "        [[ 0.0626],\n",
       "         [ 0.4519],\n",
       "         [-0.0115],\n",
       "         [ 0.3840]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bil(A,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cce9256f709cf973bee8f53e8976c158f678ec3d3bcdc7300f57702b0a2dce35"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('taxo': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
