2025-10-21 00:53:30,097 - train - INFO - number of trials: 1
2025-10-21 00:54:30,121 - train - INFO - UnifiedDataLoader mode: rps
	sampling_mode: 1
	batch_size: 4
	negative_size: 15
	expand_factor: 20
	cache_refresh_time: 64
	normalize_embed: True
	number_of_sib: 5
2025-10-21 00:54:30,768 - train - INFO - MatchModel(
  (p_lstm): LSTM(768, 500, batch_first=True)
  (c_lstm): LSTM(768, 500, batch_first=True)
  (p_control): Sequential(
    (0): Linear(in_features=768, out_features=500, bias=False)
    (1): ReLU()
  )
  (c_control): Sequential(
    (0): Linear(in_features=768, out_features=500, bias=False)
    (1): ReLU()
  )
  (attention_module): AttnBIM(
    (W): Bilinear(in1_features=3304, in2_features=768, out_features=1, bias=False)
  )
  (match): Enrich(
    (u): Linear(in_features=40, out_features=1, bias=False)
    (u_l): Linear(in_features=10, out_features=1, bias=False)
    (u_r): Linear(in_features=10, out_features=1, bias=False)
    (u_e): Linear(in_features=10, out_features=1, bias=False)
    (u_s): Linear(in_features=10, out_features=1, bias=False)
    (f): LeakyReLU(negative_slope=0.2)
    (W_l): Bilinear(in1_features=1268, in2_features=768, out_features=10, bias=True)
    (W_r): Bilinear(in1_features=1268, in2_features=768, out_features=10, bias=True)
    (W): Bilinear(in1_features=3304, in2_features=768, out_features=10, bias=True)
    (V_l): Linear(in_features=2036, out_features=10, bias=False)
    (V_r): Linear(in_features=2036, out_features=10, bias=False)
    (V): Linear(in_features=4072, out_features=10, bias=False)
    (W_s): Bilinear(in1_features=768, in2_features=768, out_features=10, bias=True)
    (V_s): Linear(in_features=1536, out_features=10, bias=False)
    (control): Sequential(
      (0): Linear(in_features=4072, out_features=3304, bias=False)
      (1): Sigmoid()
    )
    (control_l): Sequential(
      (0): Linear(in_features=2036, out_features=1268, bias=False)
      (1): Sigmoid()
    )
    (control_r): Sequential(
      (0): Linear(in_features=2036, out_features=1268, bias=False)
      (1): Sigmoid()
    )
    (control_s): Sequential(
      (0): Linear(in_features=1536, out_features=768, bias=False)
      (1): Sigmoid()
    )
  )
  (embedding): Embedding(29655, 768)
  (bert_embedding): Embedding(29655, 768)
)
Trainable parameters: 79028664
2025-10-21 00:54:31,195 - trainer - WARNING - Warning: TensorboardX visualization is configured to use, but currently not installed on this machine. Please install the package by 'pip install tensorboardx' command or turn off the option in the 'config.json' file.
2025-10-21 02:05:25,624 - trainer - INFO -     epoch          : 1
2025-10-21 02:05:25,625 - trainer - INFO -     loss           : 0.7647551010032247
2025-10-21 02:05:25,625 - trainer - INFO -     val_macro_mr   : 8036.042126190477
2025-10-21 02:05:25,625 - trainer - INFO -     val_micro_mr   : 6841.380803011292
2025-10-21 02:05:25,625 - trainer - INFO -     val_hit_at_1   : 0.00878293601003764
2025-10-21 02:05:25,625 - trainer - INFO -     val_hit_at_5   : 0.08531994981179424
2025-10-21 02:05:25,625 - trainer - INFO -     val_hit_at_10  : 0.13676286072772897
2025-10-21 02:05:25,625 - trainer - INFO -     val_precision_at_1: 0.014
2025-10-21 02:05:25,625 - trainer - INFO -     val_precision_at_5: 0.0272
2025-10-21 02:05:25,625 - trainer - INFO -     val_precision_at_10: 0.0218
2025-10-21 02:05:25,625 - trainer - INFO -     val_mrr_scaled_10: 0.21658356001238527
2025-10-21 02:07:32,281 - trainer - INFO - Saving current best: model_best.pth ...
2025-10-21 03:17:17,129 - trainer - INFO -     epoch          : 2
2025-10-21 03:17:17,130 - trainer - INFO -     loss           : 0.713462212129173
2025-10-21 03:17:17,130 - trainer - INFO -     val_macro_mr   : 10364.03708095238
2025-10-21 03:17:17,131 - trainer - INFO -     val_micro_mr   : 8738.020702634882
2025-10-21 03:17:17,131 - trainer - INFO -     val_hit_at_1   : 0.038268506900878296
2025-10-21 03:17:17,131 - trainer - INFO -     val_hit_at_5   : 0.06838143036386449
2025-10-21 03:17:17,131 - trainer - INFO -     val_hit_at_10  : 0.12421580928481807
2025-10-21 03:17:17,131 - trainer - INFO -     val_precision_at_1: 0.061
2025-10-21 03:17:17,131 - trainer - INFO -     val_precision_at_5: 0.0218
2025-10-21 03:17:17,131 - trainer - INFO -     val_precision_at_10: 0.0198
2025-10-21 03:17:17,131 - trainer - INFO -     val_mrr_scaled_10: 0.21356816656815464
2025-10-21 04:26:48,793 - trainer - INFO -     epoch          : 3
2025-10-21 04:26:48,794 - trainer - INFO -     loss           : 0.701793907973716
2025-10-21 04:26:48,794 - trainer - INFO -     val_macro_mr   : 8788.286816666667
2025-10-21 04:26:48,794 - trainer - INFO -     val_micro_mr   : 7397.836888331242
2025-10-21 04:26:48,794 - trainer - INFO -     val_hit_at_1   : 0.009410288582183186
2025-10-21 04:26:48,794 - trainer - INFO -     val_hit_at_5   : 0.03889585947302384
2025-10-21 04:26:48,794 - trainer - INFO -     val_hit_at_10  : 0.08971141781681305
2025-10-21 04:26:48,794 - trainer - INFO -     val_precision_at_1: 0.015
2025-10-21 04:26:48,794 - trainer - INFO -     val_precision_at_5: 0.0124
2025-10-21 04:26:48,794 - trainer - INFO -     val_precision_at_10: 0.0143
2025-10-21 04:26:48,794 - trainer - INFO -     val_mrr_scaled_10: 0.1970546299624133
2025-10-21 05:36:18,061 - trainer - INFO -     epoch          : 4
2025-10-21 05:36:18,062 - trainer - INFO -     loss           : 0.6965336583712075
2025-10-21 05:36:18,062 - trainer - INFO -     val_macro_mr   : 10069.586776190477
2025-10-21 05:36:18,062 - trainer - INFO -     val_micro_mr   : 8480.458594730238
2025-10-21 05:36:18,062 - trainer - INFO -     val_hit_at_1   : 0.013174404015056462
2025-10-21 05:36:18,062 - trainer - INFO -     val_hit_at_5   : 0.06838143036386449
2025-10-21 05:36:18,062 - trainer - INFO -     val_hit_at_10  : 0.12986198243412797
2025-10-21 05:36:18,062 - trainer - INFO -     val_precision_at_1: 0.021
2025-10-21 05:36:18,063 - trainer - INFO -     val_precision_at_5: 0.0218
2025-10-21 05:36:18,063 - trainer - INFO -     val_precision_at_10: 0.0207
2025-10-21 05:36:18,063 - trainer - INFO -     val_mrr_scaled_10: 0.22052816146254992
2025-10-21 06:47:10,647 - trainer - INFO -     epoch          : 5
2025-10-21 06:47:10,648 - trainer - INFO -     loss           : 0.6877899250699359
2025-10-21 06:47:10,648 - trainer - INFO -     val_macro_mr   : 8853.472421428572
2025-10-21 06:47:10,648 - trainer - INFO -     val_micro_mr   : 7489.67252195734
2025-10-21 06:47:10,648 - trainer - INFO -     val_hit_at_1   : 0.0006273525721455458
2025-10-21 06:47:10,648 - trainer - INFO -     val_hit_at_5   : 0.06461731493099122
2025-10-21 06:47:10,648 - trainer - INFO -     val_hit_at_10  : 0.12923462986198245
2025-10-21 06:47:10,648 - trainer - INFO -     val_precision_at_1: 0.001
2025-10-21 06:47:10,648 - trainer - INFO -     val_precision_at_5: 0.0206
2025-10-21 06:47:10,648 - trainer - INFO -     val_precision_at_10: 0.0206
2025-10-21 06:47:10,648 - trainer - INFO -     val_mrr_scaled_10: 0.2275744624947264
2025-10-21 08:07:25,078 - trainer - INFO -     epoch          : 6
2025-10-21 08:07:25,079 - trainer - INFO -     loss           : 0.6807996775671551
2025-10-21 08:07:25,079 - trainer - INFO -     val_macro_mr   : 9609.995076190475
2025-10-21 08:07:25,079 - trainer - INFO -     val_micro_mr   : 8099.703889585947
2025-10-21 08:07:25,079 - trainer - INFO -     val_hit_at_1   : 0.013801756587202008
2025-10-21 08:07:25,079 - trainer - INFO -     val_hit_at_5   : 0.07465495608531995
2025-10-21 08:07:25,079 - trainer - INFO -     val_hit_at_10  : 0.13488080301129235
2025-10-21 08:07:25,079 - trainer - INFO -     val_precision_at_1: 0.022
2025-10-21 08:07:25,079 - trainer - INFO -     val_precision_at_5: 0.0238
2025-10-21 08:07:25,079 - trainer - INFO -     val_precision_at_10: 0.0215
2025-10-21 08:07:25,079 - trainer - INFO -     val_mrr_scaled_10: 0.2285174313673258
2025-10-21 09:16:47,834 - trainer - INFO -     epoch          : 7
2025-10-21 09:16:47,835 - trainer - INFO -     loss           : 0.6779562376346897
2025-10-21 09:16:47,835 - trainer - INFO -     val_macro_mr   : 8535.395914285717
2025-10-21 09:16:47,835 - trainer - INFO -     val_micro_mr   : 7252.200125470515
2025-10-21 09:16:47,835 - trainer - INFO -     val_hit_at_1   : 0.02383939774153074
2025-10-21 09:16:47,835 - trainer - INFO -     val_hit_at_5   : 0.07528230865746549
2025-10-21 09:16:47,835 - trainer - INFO -     val_hit_at_10  : 0.14303638644918445
2025-10-21 09:16:47,836 - trainer - INFO -     val_precision_at_1: 0.038
2025-10-21 09:16:47,836 - trainer - INFO -     val_precision_at_5: 0.024
2025-10-21 09:16:47,836 - trainer - INFO -     val_precision_at_10: 0.0228
2025-10-21 09:16:47,836 - trainer - INFO -     val_mrr_scaled_10: 0.2313412067295638
2025-10-21 10:29:51,273 - trainer - INFO -     epoch          : 8
2025-10-21 10:29:51,274 - trainer - INFO -     loss           : 0.6717565429712397
2025-10-21 10:29:51,274 - trainer - INFO -     val_macro_mr   : 7919.219073809524
2025-10-21 10:29:51,274 - trainer - INFO -     val_micro_mr   : 6801.331242158093
2025-10-21 10:29:51,274 - trainer - INFO -     val_hit_at_1   : 0.02258469259723965
2025-10-21 10:29:51,274 - trainer - INFO -     val_hit_at_5   : 0.06524466750313676
2025-10-21 10:29:51,275 - trainer - INFO -     val_hit_at_10  : 0.13111668757841907
2025-10-21 10:29:51,275 - trainer - INFO -     val_precision_at_1: 0.036
2025-10-21 10:29:51,275 - trainer - INFO -     val_precision_at_5: 0.0208
2025-10-21 10:29:51,275 - trainer - INFO -     val_precision_at_10: 0.0209
2025-10-21 10:29:51,275 - trainer - INFO -     val_mrr_scaled_10: 0.22604689248920726
2025-10-21 10:31:59,485 - trainer - INFO - Saving current best: model_best.pth ...
2025-10-21 11:42:18,806 - trainer - INFO -     epoch          : 9
2025-10-21 11:42:18,849 - trainer - INFO -     loss           : 0.6675399189563304
2025-10-21 11:42:18,849 - trainer - INFO -     val_macro_mr   : 8163.980561904762
2025-10-21 11:42:18,850 - trainer - INFO -     val_micro_mr   : 6889.658092848181
2025-10-21 11:42:18,850 - trainer - INFO -     val_hit_at_1   : 0.010037641154328732
2025-10-21 11:42:18,850 - trainer - INFO -     val_hit_at_5   : 0.08971141781681305
2025-10-21 11:42:18,850 - trainer - INFO -     val_hit_at_10  : 0.18318695106649938
2025-10-21 11:42:18,850 - trainer - INFO -     val_precision_at_1: 0.016
2025-10-21 11:42:18,850 - trainer - INFO -     val_precision_at_5: 0.0286
2025-10-21 11:42:18,851 - trainer - INFO -     val_precision_at_10: 0.0292
2025-10-21 11:42:18,851 - trainer - INFO -     val_mrr_scaled_10: 0.25925153376680216
2025-10-21 12:52:37,259 - trainer - INFO -     epoch          : 10
2025-10-21 12:52:37,276 - trainer - INFO -     loss           : 0.6617733034304466
2025-10-21 12:52:37,276 - trainer - INFO -     val_macro_mr   : 7724.453780952381
2025-10-21 12:52:37,276 - trainer - INFO -     val_micro_mr   : 6588.319949811794
2025-10-21 12:52:37,276 - trainer - INFO -     val_hit_at_1   : 0.01819322459222083
2025-10-21 12:52:37,276 - trainer - INFO -     val_hit_at_5   : 0.09222082810539524
2025-10-21 12:52:37,276 - trainer - INFO -     val_hit_at_10  : 0.15181932245922208
2025-10-21 12:52:37,276 - trainer - INFO -     val_precision_at_1: 0.029
2025-10-21 12:52:37,276 - trainer - INFO -     val_precision_at_5: 0.0294
2025-10-21 12:52:37,277 - trainer - INFO -     val_precision_at_10: 0.0242
2025-10-21 12:52:37,277 - trainer - INFO -     val_mrr_scaled_10: 0.2428122722585595
2025-10-21 12:52:50,847 - trainer - INFO - Saving current best: model_best.pth ...
2025-10-21 14:25:25,235 - trainer - INFO -     epoch          : 11
2025-10-21 14:25:25,236 - trainer - INFO -     loss           : 0.6600340865304576
2025-10-21 14:25:25,236 - trainer - INFO -     val_macro_mr   : 7700.502802380953
2025-10-21 14:25:25,237 - trainer - INFO -     val_micro_mr   : 6529.556461731493
2025-10-21 14:25:25,237 - trainer - INFO -     val_hit_at_1   : 0.021957340025094103
2025-10-21 14:25:25,237 - trainer - INFO -     val_hit_at_5   : 0.09849435382685069
2025-10-21 14:25:25,237 - trainer - INFO -     val_hit_at_10  : 0.15558343789209536
2025-10-21 14:25:25,237 - trainer - INFO -     val_precision_at_1: 0.035
2025-10-21 14:25:25,237 - trainer - INFO -     val_precision_at_5: 0.0314
2025-10-21 14:25:25,237 - trainer - INFO -     val_precision_at_10: 0.0248
2025-10-21 14:25:25,237 - trainer - INFO -     val_mrr_scaled_10: 0.2449292732317937
2025-10-21 14:25:39,655 - trainer - INFO - Saving current best: model_best.pth ...
2025-10-21 15:57:46,801 - trainer - INFO -     epoch          : 12
2025-10-21 15:57:46,814 - trainer - INFO -     loss           : 0.6555896630159926
2025-10-21 15:57:46,814 - trainer - INFO -     val_macro_mr   : 8166.2041
2025-10-21 15:57:46,814 - trainer - INFO -     val_micro_mr   : 6960.237139272271
2025-10-21 15:57:46,814 - trainer - INFO -     val_hit_at_1   : 0.03889585947302384
2025-10-21 15:57:46,814 - trainer - INFO -     val_hit_at_5   : 0.11041405269761606
2025-10-21 15:57:46,814 - trainer - INFO -     val_hit_at_10  : 0.1618569636135508
2025-10-21 15:57:46,815 - trainer - INFO -     val_precision_at_1: 0.062
2025-10-21 15:57:46,815 - trainer - INFO -     val_precision_at_5: 0.0352
2025-10-21 15:57:46,815 - trainer - INFO -     val_precision_at_10: 0.0258
2025-10-21 15:57:46,815 - trainer - INFO -     val_mrr_scaled_10: 0.24511779936181216
2025-10-21 17:34:10,223 - trainer - INFO -     epoch          : 13
2025-10-21 17:34:10,225 - trainer - INFO -     loss           : 0.6513244703623267
2025-10-21 17:34:10,226 - trainer - INFO -     val_macro_mr   : 6593.215916666666
2025-10-21 17:34:10,226 - trainer - INFO -     val_micro_mr   : 5608.278544542032
2025-10-21 17:34:10,226 - trainer - INFO -     val_hit_at_1   : 0.033249686323713924
2025-10-21 17:34:10,226 - trainer - INFO -     val_hit_at_5   : 0.11794228356336262
2025-10-21 17:34:10,226 - trainer - INFO -     val_hit_at_10  : 0.17754077791718947
2025-10-21 17:34:10,226 - trainer - INFO -     val_precision_at_1: 0.053
2025-10-21 17:34:10,226 - trainer - INFO -     val_precision_at_5: 0.0376
2025-10-21 17:34:10,226 - trainer - INFO -     val_precision_at_10: 0.0283
2025-10-21 17:34:10,226 - trainer - INFO -     val_mrr_scaled_10: 0.2559704502436308
2025-10-21 17:34:23,509 - trainer - INFO - Saving current best: model_best.pth ...
2025-10-21 18:57:40,893 - trainer - INFO -     epoch          : 14
2025-10-21 18:57:40,894 - trainer - INFO -     loss           : 0.6515137362995691
2025-10-21 18:57:40,894 - trainer - INFO -     val_macro_mr   : 7913.872826190475
2025-10-21 18:57:40,894 - trainer - INFO -     val_micro_mr   : 6741.019447929736
2025-10-21 18:57:40,894 - trainer - INFO -     val_hit_at_1   : 0.02383939774153074
2025-10-21 18:57:40,894 - trainer - INFO -     val_hit_at_5   : 0.11292346298619825
2025-10-21 18:57:40,894 - trainer - INFO -     val_hit_at_10  : 0.1794228356336261
2025-10-21 18:57:40,894 - trainer - INFO -     val_precision_at_1: 0.038
2025-10-21 18:57:40,894 - trainer - INFO -     val_precision_at_5: 0.036
2025-10-21 18:57:40,894 - trainer - INFO -     val_precision_at_10: 0.0286
2025-10-21 18:57:40,894 - trainer - INFO -     val_mrr_scaled_10: 0.2602256022799425
2025-10-21 20:24:43,024 - trainer - INFO -     epoch          : 15
2025-10-21 20:24:43,047 - trainer - INFO -     loss           : 0.6438008946492418
2025-10-21 20:24:43,048 - trainer - INFO -     val_macro_mr   : 6739.4043619047625
2025-10-21 20:24:43,048 - trainer - INFO -     val_micro_mr   : 5722.156210790465
2025-10-21 20:24:43,048 - trainer - INFO -     val_hit_at_1   : 0.024466750313676285
2025-10-21 20:24:43,048 - trainer - INFO -     val_hit_at_5   : 0.09786700125470514
2025-10-21 20:24:43,048 - trainer - INFO -     val_hit_at_10  : 0.1794228356336261
2025-10-21 20:24:43,048 - trainer - INFO -     val_precision_at_1: 0.039
2025-10-21 20:24:43,048 - trainer - INFO -     val_precision_at_5: 0.0312
2025-10-21 20:24:43,048 - trainer - INFO -     val_precision_at_10: 0.0286
2025-10-21 20:24:43,048 - trainer - INFO -     val_mrr_scaled_10: 0.2578166142694411
